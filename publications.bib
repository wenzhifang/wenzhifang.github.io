@article{fang2024hierarchical,
  title={Hierarchical federated learning with multi-timescale gradient correction},
  author={Fang, Wenzhi and Han, Dong-Jun and Chen, Evan and Wang, Shiqiang and Brinton, Christopher G},
  journal={NeurIPS},
  year={2024}
}
@article{fang2022communication,
  title={Communication-efficient stochastic zeroth-order optimization for federated learning},
  author={Fang, Wenzhi and Yu, Ziyi and Jiang, Yuning and Shi, Yuanming and Jones, Colin N and Zhou, Yong},
  journal={IEEE Transactions on Signal Processing},
  volume={70},
  pages={5058--5073},
  year={2022},
  publisher={IEEE}
}
@article{fang2025federated,
  title={Federated Learning over Hierarchical Wireless Networks: Training Latency Minimization via Submodel Partitioning},
  author={Fang, Wenzhi and Han, Dong-Jun and Brinton, Christopher G},
  journal={IEEEACM transactions on networking},
  year={2025},
  publisher={IEEE/ACM Transactions on Networking}
}
@inproceedings{fang2024submodel,
  title={Submodel partitioning in hierarchical federated learning: Algorithm design and convergence analysis},
  author={Fang, Wenzhi and Han, Dong-Jun and Brinton, Christopher G},
  booktitle={ICC 2024-IEEE International Conference on Communications},
  pages={268--273},
  year={2024},
  organization={IEEE}
}
@misc{fang2025federatedsketchingloraondevice,
      title={Federated Sketching LoRA: On-Device Collaborative Fine-Tuning of Large Language Models}, 
      author={Wenzhi Fang and Dong-Jun Han and Liangqi Yuan and Seyyedali Hosseinalipour and Christopher G. Brinton},
      year={2025},
      eprint={2501.19389},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2501.19389}, 
}